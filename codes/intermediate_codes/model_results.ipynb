{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7bef2b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import psycopg2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from xgboost import plot_importance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor   \n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "plt.style.use('bmh')\n",
    "from pandas import Series, DataFrame\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "import math\n",
    "import traceback\n",
    "import sys\n",
    "import re\n",
    "import datetime\n",
    "datetime.timedelta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8ee021fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for OOT resutls\n",
    "def OOT_results(xgb_model,OOT):\n",
    "    t_opt=0.5\n",
    "    #print(\"Threshold value is: %.2f\" % t_opt)\n",
    "    \n",
    "    y_pred = xgb_model.predict_proba(OOT.drop(columns=['Loan_ID','paid_flag']))[:,1]\n",
    "    fp_r, tp_r, t = metrics.roc_curve(OOT['paid_flag'], y_pred)\n",
    "    #tp_r, fpr, t = metrics.roc_curve(y_test, y_pred)\n",
    "    auc = metrics.auc(fp_r, tp_r)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(fp_r, tp_r, label=\"AUC = %.2f\" % auc)\n",
    "    plt.plot([0,1],[0,1],\"r--\")\n",
    "    plt.ylabel(\"TP rate\")\n",
    "    plt.xlabel(\"FP rate\")\n",
    "    plt.legend(loc=4)\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.show()\n",
    "    \n",
    "    y_OOT_pred = (xgb_model.predict_proba(OOT.drop(columns=['Loan_ID','paid_flag']))[:,1])\n",
    "    OOT_pred_label = (xgb_model.predict_proba(OOT.drop(columns=['Loan_ID','paid_flag']))[:,1] >=t_opt).astype(int)\n",
    "    df_OOT=pd.DataFrame({'Loan_ID':OOT['Loan_ID'],'prob':y_OOT_pred,'pred_label':OOT_pred_label,'actual_label':OOT['paid_flag']})\n",
    "    df_OOT=df_OOT.sort_values('prob',ascending=False).reset_index()\n",
    "\n",
    "    total_1=sum(df_OOT['actual_label'])\n",
    "\n",
    "    print(\"Results on top 1% data : \")\n",
    "    df_temp=df_OOT[:math.ceil(len(df_OOT)/100*1)]\n",
    "    total_sub_1=sum(df_OOT['actual_label'])\n",
    "    print(\"precision : \",sum(df_temp['actual_label'])/len(df_temp)*100)\n",
    "    print(\"recall : \", sum(df_temp['actual_label'])/sum(df_OOT['actual_label'])*100, \"\\n\")\n",
    "\n",
    "    print(\"Results on top 5% data : \")\n",
    "    df_temp=df_OOT[:math.ceil(len(df_OOT)/100*5)]\n",
    "    total_sub_1=sum(df_OOT['actual_label'])\n",
    "    print(\"precision : \",sum(df_temp['actual_label'])/len(df_temp)*100)\n",
    "    print(\"recall : \", sum(df_temp['actual_label'])/sum(df_OOT['actual_label'])*100, \"\\n\")\n",
    "\n",
    "    print(\"Results on top 10% data : \")\n",
    "    df_temp=df_OOT[:math.ceil(len(df_OOT)/100*10)]\n",
    "    total_sub_1=sum(df_OOT['actual_label'])\n",
    "    print(\"precision : \",sum(df_temp['actual_label'])/len(df_temp)*100)\n",
    "    print(\"recall : \",sum(df_temp['actual_label'])/sum(df_OOT['actual_label'])*100, \"\\n\")\n",
    "\n",
    "    print(\"Results on top 30% data : \")\n",
    "    df_temp=df_OOT[:math.ceil(len(df_OOT)/100*30)]\n",
    "    total_sub_1=sum(df_OOT['actual_label'])\n",
    "    print(\"precision : \",sum(df_temp['actual_label'])/len(df_temp)*100)\n",
    "    print(\"recall : \", sum(df_temp['actual_label'])/sum(df_OOT['actual_label'])*100, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2c15d7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_predictions_to_bucket(pred):\n",
    "    if pred <=0.02:\n",
    "        return 1\n",
    "    elif pred <=0.1:\n",
    "        return 2\n",
    "    elif pred <=1.0:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0c803d51",
   "metadata": {},
   "outputs": [],
   "source": [
    " #creating risk segment\n",
    "def risk_segment(pred):\n",
    "        if pred==-1:\n",
    "            return 'no_risk'\n",
    "        elif pred==1:\n",
    "            return 'high_risk'\n",
    "        elif pred ==2:\n",
    "            return 'medium_risk'\n",
    "        elif pred ==3:\n",
    "            return 'low_risk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8c5979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_results(xgb_model,ST1,ST2,ST3,paid_file,allocation,comms):\n",
    "    \n",
    "    ST2.drop(['L3_index'],axis=1,inplace=True)\n",
    "    \n",
    "    \n",
    "    ST3['Loan_ID']=ST3['Loan_ID'].astype(int)\n",
    "    ST2['L3_Loan_ID']=ST2['L3_Loan_ID'].astype(int)\n",
    "    \n",
    "    df_temp=pd.merge(ST3,ST2,how='left',left_on=['Loan_ID'],right_on=['L3_Loan_ID'])\n",
    "    df_temp.shape\n",
    "    df=pd.merge(df_temp,ST1,how='left',left_on=['Loan_ID'],right_on=['Loan_ID'])\n",
    "    df.shape\n",
    "    \n",
    "    OOT=df.copy()\n",
    "    \n",
    "    ## Selecting columns based on higher IV values:\n",
    "    sel_col=[\n",
    "    'month',\n",
    "    'Loan_ID',\n",
    "    'mean_call_duration',\n",
    "    'call_picked_%',\n",
    "    'call_response_%',\n",
    "    'L2_call_duration',\n",
    "    'L2_call_picked',\n",
    "    'L2_call_responsive',\n",
    "    'L2_Promiseto Pay',\n",
    "    'L1_call_duration',\n",
    "    'L1_call_picked',\n",
    "    'L1_call_responsive',\n",
    "    'L1_Promiseto Pay',\n",
    "    'L1_RPC',\n",
    "    'Principle_due_%',\n",
    "    #'Charges_due_%',\n",
    "    'Panelty_due_%',\n",
    "    'Principle_paid_%',\n",
    "    'paid_flag'    \n",
    "    ]\n",
    "\n",
    "    #removing some variables\n",
    "    sel_col.remove('month')\n",
    "    sel_col.remove('paid_flag')\n",
    "\n",
    "    ## Dropping columns with higher VIF value:\n",
    "    #OOT.drop(['call_picked_%'],axis=1,inplace=True)\n",
    "\n",
    "    ##Adding 1 feature\n",
    "    OOT['L2_RPC']=0\n",
    "\n",
    "    OOT=OOT[sel_col].copy()\n",
    "\n",
    "    y_pred = xgb_model.predict_proba(OOT.drop(columns=['Loan_ID']))[:,1]\n",
    "\n",
    "    \n",
    "    paid_file.shape\n",
    "    paid_file['Date Repaid'] = pd.to_datetime(paid_file['Date Repaid'], errors='coerce')\n",
    "    paid_file['day']=paid_file['Date Repaid'].dt.day\n",
    "    paid_file.shape\n",
    "    paid_file=paid_file[(paid_file['day']>=0) & (paid_file['day']<=31)]\n",
    "    paid_file.shape\n",
    "\n",
    "    #paid_file.drop(['paid_flag'],axis=1,inplace=True)\n",
    "    paid_file['paid']=1\n",
    "    paid_file=paid_file.rename(columns={'AgreementNumber':'Loan_ID','paid':'paid_flag'})\n",
    "    paid_file.drop_duplicates(subset =\"Loan_ID\", keep = 'first', inplace = True)\n",
    "    paid_file.shape\n",
    "    OOT=pd.merge(OOT,paid_file[['Loan_ID','paid_flag']],how='left',left_on='Loan_ID',right_on='Loan_ID')\n",
    "    OOT.shape\n",
    "    OOT.columns\n",
    "    OOT['paid_flag']=OOT['paid_flag'].fillna(0)\n",
    "    #OOT_results\n",
    "    OOT_results(xgb_model,OOT)\n",
    "    \n",
    "    #Creating june month results\n",
    "    results=pd.DataFrame({'Loan_ID':list(OOT['Loan_ID']),'Prob':list(y_pred)})\n",
    "    \n",
    "    results_updated=results.copy()\n",
    "   \n",
    "    df2=results_updated.copy()\n",
    "\n",
    "    #### Creation of probability buckets\n",
    "\n",
    "    l=pd.merge(df2,paid_file,how='left',left_on='Loan_ID',right_on='Loan_ID')\n",
    "    l['paid_flag']=l['paid_flag'].fillna(0)\n",
    "    l_paid=l[l.paid_flag==1]\n",
    "    l_paid.shape\n",
    "\n",
    "\n",
    "    l.loc[:, 'prob_bucket'] = l['Prob'].apply(lambda x: convert_predictions_to_bucket(x))\n",
    "    l['prob_bucket'].value_counts()\n",
    "\n",
    "    paid_rate = l.groupby(['prob_bucket'])['paid_flag'].agg(['sum', 'count']).reset_index()\n",
    "    paid_rate['conversion_rate']=paid_rate['sum']/paid_rate['count']*100\n",
    "    kk=paid_rate.sort_values('prob_bucket',ascending=False)\n",
    "\n",
    "    #sum(l['paid_flag']/len(l['Loan_ID']))*100\n",
    "    \n",
    " #   print(l.columns)\n",
    " #   print(l.groupby(['prob_bucket']).agg({'Loan_ID':'count'}))\n",
    "\n",
    "    ## Saving updated ranking\n",
    "\n",
    "    allocation=allocation[allocation['DPD']>90]\n",
    "    allocation.shape\n",
    "\n",
    "    set_A_risk=pd.merge(allocation[['AgreementNumber','OS']],l[['Loan_ID','Prob','prob_bucket']],how='left',left_on='AgreementNumber',right_on='Loan_ID')\n",
    "    set_A_risk['AgreementNumber']=set_A_risk['AgreementNumber'].astype(int).astype(str)\n",
    "    \n",
    " #   print(set_A_risk.groupby(['prob_bucket']).agg({'AgreementNumber':'count'}))\n",
    "    \n",
    "    paid_file['Loan_ID']=paid_file['Loan_ID'].astype(int).astype(str)\n",
    "    set_A_risk=pd.merge(set_A_risk,paid_file[['Loan_ID','paid_flag']],how='left',left_on='AgreementNumber',right_on='Loan_ID')\n",
    "\n",
    "\n",
    "#    print(set_A_risk.groupby(['prob_bucket']).agg({'AgreementNumber':'count'}))\n",
    "    \n",
    "\n",
    "#     S_AMT=pd.read_excel('RR_jul_S_AMT.xlsx')\n",
    "#     S_AMT.shape\n",
    "\n",
    "#     set_A_risk\n",
    "\n",
    "#     set_A_risk.shape\n",
    "#     S_AMT['Loan id']=S_AMT['Loan id'].astype(int).astype(str)\n",
    "#     #june22_paid['Loan_ID']=june22_paid['Loan_ID'].astype(int).astype(str)\n",
    "#     set_A_risk=pd.merge(set_A_risk,S_AMT,how='left',left_on='AgreementNumber',right_on='Loan id')\n",
    "#     set_A_risk.shape\n",
    "\n",
    "    # set_A_risk.drop(['Loan_ID_x','Loan_ID_y'],axis=1,inplace=True)\n",
    "    set_A_risk['paid_flag']=set_A_risk['paid_flag'].fillna(0)\n",
    "    set_A_risk['prob_bucket']=set_A_risk['prob_bucket'].fillna(-1)\n",
    "\n",
    "    set_A_risk.loc[:, 'risk_segment'] = set_A_risk['prob_bucket'].apply(lambda x: risk_segment(x))\n",
    "    #set_A_risk['risk_segment'].value_counts()\n",
    "    \n",
    " #   print(set_A_risk.groupby(['prob_bucket']).agg({'AgreementNumber':'count'}))\n",
    "  #  print(set_A_risk.groupby(['risk_segment']).agg({'AgreementNumber':'count'}))\n",
    "    \n",
    "    return set_A_risk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b99b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f050e38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba34293c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf6e2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6214daa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3733f38e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e8c233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9d408a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
