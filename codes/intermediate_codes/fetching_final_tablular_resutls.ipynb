{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f455005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import psycopg2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn import metrics\n",
    "from xgboost import plot_importance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor   \n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "plt.style.use('bmh')\n",
    "from pandas import Series, DataFrame\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "import traceback\n",
    "import sys\n",
    "import re\n",
    "import datetime\n",
    "datetime.timedelta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50689633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk_seg(pred):\n",
    "    if pred<=1000:\n",
    "        return 'low_priority'\n",
    "    elif pred<=5000:\n",
    "        return 'medium_priority'\n",
    "    else:\n",
    "        return 'high_priority'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb850aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func1(risk_segment,allocation,existing_comms,paid_file,S_AMT):\n",
    "    print(risk_segment.shape)\n",
    "    \n",
    "    #risk_segment.shape\n",
    "    S_AMT['Loan id']=S_AMT['Loan id'].astype(int).astype(str)\n",
    "    risk_segment['AgreementNumber']=risk_segment['AgreementNumber'].astype(int).astype(str)\n",
    "    #june22_paid['Loan_ID']=june22_paid['Loan_ID'].astype(int).astype(str)\n",
    "    risk_segment=pd.merge(risk_segment,S_AMT,how='left',left_on='AgreementNumber',right_on='Loan id')\n",
    "    risk_segment.shape\n",
    "    \n",
    "    \n",
    "    risk_segment.loc[:, 'risk_priority'] = risk_segment['S_AMT'].apply(lambda x: risk_seg(x))\n",
    "    risk_segment['risk_priority'].value_counts()\n",
    "    \n",
    "    \n",
    "    #existing_comms['Loan_ID']=existing_comms['Loan_ID'].astype(int).astype(str)\n",
    "    \n",
    "    existing_comms['Call_Start_Time'] = pd.to_datetime(existing_comms['Call_Start_Time'], errors='coerce')\n",
    "    existing_comms['Call_End_Time'] = pd.to_datetime(existing_comms['Call_End_Time'], errors='coerce')\n",
    "    existing_comms['call_duration'] = (existing_comms.Call_End_Time-existing_comms.Call_Start_Time).dt.total_seconds()\n",
    "\n",
    "    def process_call_duration(row):\n",
    "        if row['Dialer_Disposition'] in ['Answered', 'Agent_Answered']:\n",
    "            return row['call_duration']\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    existing_comms['call_duration'] = existing_comms.apply(lambda x: process_call_duration(x), axis=1)\n",
    "\n",
    "\n",
    "    existing_comms['call_picked']=existing_comms['call_duration'].apply(lambda x: 1 if x>0 else 0)\n",
    "    existing_comms['call_responsive']=existing_comms['call_duration'].apply(lambda x: 1 if x>=30 else 0)\n",
    "\n",
    "    ## Aggregating the data\n",
    "    existing_comms_v2=existing_comms.groupby('Loan_ID').agg(calls_count=('Contact No ','count'),\n",
    "                                             total_call_duration=('call_duration','sum'),\n",
    "                                             mean_call_duration=('call_duration','mean'),\n",
    "                                             median_call_duration=('call_duration','median'),\n",
    "                                             total_call_picked=('call_picked','sum'),\n",
    "                                             total_call_responsive=('call_responsive','sum')\n",
    "                                            # paid_flag=('paid_flag','first')\n",
    "                                             ).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "    existing_comms_v2['call_picked_%']=existing_comms_v2['total_call_picked']/existing_comms_v2['calls_count']*100\n",
    "    existing_comms_v2['call_response_%']=existing_comms_v2['total_call_responsive']/existing_comms_v2['calls_count']*100\n",
    "\n",
    "    existing_comms_v2['call_picked_flag']=existing_comms_v2['total_call_picked'].apply(lambda x: 1 if x>0 else 0)\n",
    "    \n",
    "    \n",
    "    risk_segment['AgreementNumber']=risk_segment['AgreementNumber'].astype(int).astype(str)\n",
    "    #existing_comms_v2['Loan_ID']=existing_comms_v2['Loan_ID'].astype(int).astype(str)\n",
    "    #existing_comms_v2['Loan_ID']=existing_comms_v2['Loan_ID'].astype(int).astype(str)\n",
    "    #Jan22_raw['AgreementNumber']=Jan22_raw['AgreementNumber'].astype(int).astype(str)\n",
    "    risk_segment_picked=pd.merge(risk_segment,existing_comms_v2[['Loan_ID','call_picked_flag']],how='left',left_on='AgreementNumber',right_on='Loan_ID')\n",
    "    risk_segment_picked_v2=pd.merge(risk_segment,existing_comms_v2,how='left',left_on='AgreementNumber',right_on='Loan_ID')\n",
    "\n",
    "    risk_segment_picked=risk_segment_picked.drop(['OS', 'Loan_ID_x','Loan_ID_y', 'Loan id','Loan_ID'],axis=1)\n",
    "    risk_segment_picked_v2=risk_segment_picked_v2.drop(['OS', 'Loan_ID_x','Loan_ID_y', 'Loan id','Loan_ID'],axis=1)\n",
    "    \n",
    "    return risk_segment_picked,risk_segment_picked_v2\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff34c452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func2(risk_segment,allocation,existing_comms,paid_file):\n",
    "    \n",
    "    ## converting loan ID to numeric datatype\n",
    "    \n",
    "    existing_comms=existing_comms[existing_comms['Loan_ID'].isin(allocation['AgreementNumber'])]\n",
    "    existing_comms['Loan_ID']=pd.to_numeric(existing_comms['Loan_ID'], errors='coerce')\n",
    "\n",
    "    \n",
    "    existing_comms['Call_Start_Time'] = pd.to_datetime(existing_comms['Call_Start_Time'], errors='coerce')\n",
    "    existing_comms['Call_End_Time'] = pd.to_datetime(existing_comms['Call_End_Time'], errors='coerce')\n",
    "    existing_comms['call_duration'] = (existing_comms.Call_End_Time-existing_comms.Call_Start_Time).dt.total_seconds()\n",
    "\n",
    "    def process_call_duration(row):\n",
    "        if row['Dialer_Disposition'] in ['Answered', 'Agent_Answered']:\n",
    "            return row['call_duration']\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    existing_comms['call_duration'] = existing_comms.apply(lambda x: process_call_duration(x), axis=1)\n",
    "\n",
    "\n",
    "    existing_comms['call_picked']=existing_comms['call_duration'].apply(lambda x: 1 if x>0 else 0)\n",
    "    existing_comms['call_responsive']=existing_comms['call_duration'].apply(lambda x: 1 if x>=30 else 0)\n",
    "\n",
    "    ## Aggregating the data\n",
    "    existing_comms_v2=existing_comms.groupby('Loan_ID').agg(calls_count=('Contact No ','count'),\n",
    "                                             total_call_duration=('call_duration','sum'),\n",
    "                                             mean_call_duration=('call_duration','mean'),\n",
    "                                             median_call_duration=('call_duration','median'),\n",
    "                                             total_call_picked=('call_picked','sum'),\n",
    "                                             total_call_responsive=('call_responsive','sum')\n",
    "                                            # paid_flag=('paid_flag','first')\n",
    "                                             ).reset_index()\n",
    "\n",
    "    existing_comms_v2['call_picked_%']=existing_comms_v2['total_call_picked']/existing_comms_v2['calls_count']*100\n",
    "    existing_comms_v2['call_response_%']=existing_comms_v2['total_call_responsive']/existing_comms_v2['calls_count']*100\n",
    "    \n",
    "    df_picked=existing_comms_v2.copy()\n",
    "    \n",
    "    df_picked.shape\n",
    "    \n",
    "    #Changing Dates\n",
    "    paid_file.shape\n",
    "    paid_file['Date Repaid'] = pd.to_datetime(paid_file['Date Repaid'], errors='coerce')\n",
    "    paid_file['day']=paid_file['Date Repaid'].dt.day\n",
    "    paid_file.shape\n",
    "    #paid_file=june22_paid[(paid_file['day']>=0) & (june22_paid['day']<=31)]\n",
    "    paid_file.shape\n",
    "\n",
    "    #june22_paid.drop(['paid_flag'],axis=1,inplace=True)\n",
    "    paid_file['paid']=1\n",
    "    paid_file=paid_file.rename(columns={'AgreementNumber':'Loan_ID','paid':'paid_flag'})\n",
    "    paid_file.drop_duplicates(subset =\"Loan_ID\", keep = 'first', inplace = True)\n",
    "    paid_file.shape\n",
    "\n",
    "\n",
    "    paid_file['Loan_ID']=paid_file['Loan_ID'].astype(int).astype(str)\n",
    "    #S_AMT['Loan id']=S_AMT['Loan id'].astype(int).astype(str)\n",
    "\n",
    "#     paid_file=pd.merge(paid_file ,S_AMT,how='left',left_on='Loan_ID',right_on='Loan id')\n",
    "#     paid_file.shape\n",
    "\n",
    "    allocation['AgreementNumber']=allocation['AgreementNumber'].astype(int).astype(str)\n",
    "    df_picked['Loan_ID']=df_picked['Loan_ID'].astype(int).astype(str)\n",
    "\n",
    "    df_picked=pd.merge(allocation,df_picked[['Loan_ID','total_call_picked','calls_count','total_call_duration']],how='left',left_on='AgreementNumber',right_on='Loan_ID')\n",
    "    df_picked.shape\n",
    "    df_picked=pd.merge(df_picked,paid_file[['Loan_ID','paid_flag','Repayment']],how='left',left_on='AgreementNumber',right_on='Loan_ID')\n",
    "    df_picked.shape\n",
    "\n",
    "\n",
    "    df_picked['paid_flag']=df_picked['paid_flag'].fillna(0)\n",
    "    df_picked['picked_flag']=df_picked['total_call_picked'].apply(lambda x : 1 if x>0 else 0)\n",
    "    \n",
    "    kk=df_picked.groupby('picked_flag').agg(comms_count=('calls_count','sum'),cust_count=('AgreementNumber','count'),paid_count=('paid_flag','sum'),paid_amount=('Repayment','sum'),total_time_spent=('total_call_duration','sum')).reset_index()\n",
    "\n",
    "    kk['churn_per_paid_cust']=round(kk['comms_count']/kk['paid_count'],1)\n",
    "    kk['paid_dist']=round(kk['paid_count']/sum(kk['paid_count'])*100,2)\n",
    "    kk['paid_rate']=round(kk['paid_count']/kk['cust_count']*100,2)\n",
    "    \n",
    "    return kk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d62987dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func3(risk_segment_file_to_internal_picked,tag):\n",
    "    print(tag[0])\n",
    "    print(tag[1])\n",
    "    print(tag[2])\n",
    "    print(tag[3])\n",
    "    \n",
    "    risk_segment_order=['low_risk','medium_risk','high_risk']\n",
    "    risk_priority_order=['low_priority','medium_priority','high_priority']\n",
    "    \n",
    "    val_pred_par = pd.crosstab(risk_segment_file_to_internal_picked.risk_segment, risk_segment_file_to_internal_picked.risk_priority,values=risk_segment_file_to_internal_picked['calls_count'],aggfunc=np.sum,\n",
    "                   normalize=False, margins=True)\n",
    "    val_pred_par1 = pd.crosstab(risk_segment_file_to_internal_picked.risk_segment, risk_segment_file_to_internal_picked.risk_priority,values=risk_segment_file_to_internal_picked['flag'],aggfunc=np.sum, normalize=False, margins=True)\n",
    "    val_pred_par2 = pd.crosstab(risk_segment_file_to_internal_picked.risk_segment, risk_segment_file_to_internal_picked.risk_priority,values=risk_segment_file_to_internal_picked['paid_flag'],aggfunc=np.sum, normalize=False, margins=True)\n",
    "    val_pred_par3 = pd.crosstab(risk_segment_file_to_internal_picked.risk_segment, risk_segment_file_to_internal_picked.risk_priority,values=risk_segment_file_to_internal_picked['S_AMT'],aggfunc=np.sum, normalize=False, margins=True)\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "    ax1 = fig.add_subplot(221)\n",
    "    sns.heatmap(val_pred_par, \n",
    "        annot=True,\n",
    "        linewidths=0.3,\n",
    "        robust=True,\n",
    "        cmap=sns.light_palette(\"seagreen\", as_cmap=True),\n",
    "        vmin=0, vmax=7, \n",
    "    #     center=0.5,\n",
    "        annot_kws={'size': 14},\n",
    "        ax=ax1, fmt='.10g'\n",
    "    )\n",
    "    ax1.set_xticklabels(\n",
    "        ax1.get_xticklabels(),\n",
    "        rotation=0,\n",
    "        horizontalalignment='center'\n",
    "    );\n",
    "    \n",
    "   \n",
    "    ax2 = fig.add_subplot(222)\n",
    "    sns.heatmap(val_pred_par1, \n",
    "        annot=True,\n",
    "        linewidths=0.3,\n",
    "        robust=True,\n",
    "        cmap=sns.light_palette(\"seagreen\", as_cmap=True),\n",
    "        vmin=0, vmax=7, \n",
    "    #     center=0.5,\n",
    "        annot_kws={'size': 14},\n",
    "        ax=ax2, fmt='.10g'\n",
    "    )\n",
    "    ax2.set_xticklabels(\n",
    "        ax2.get_xticklabels(),\n",
    "        rotation=0,\n",
    "        horizontalalignment='center'\n",
    "    );\n",
    "   \n",
    "    ax3 = fig.add_subplot(223)\n",
    "    sns.heatmap(val_pred_par2, \n",
    "        annot=True,\n",
    "        linewidths=0.3,\n",
    "        robust=True,\n",
    "        cmap=sns.light_palette(\"seagreen\", as_cmap=True),\n",
    "        vmin=0, vmax=7, \n",
    "    #     center=0.5,\n",
    "        annot_kws={'size': 14},\n",
    "        ax=ax3, fmt='.10g'\n",
    "    )\n",
    "    ax3.set_xticklabels(\n",
    "        ax3.get_xticklabels(),\n",
    "        rotation=0,\n",
    "        horizontalalignment='center'\n",
    "    );\n",
    "   \n",
    "    ax4 = fig.add_subplot(224)\n",
    "    sns.heatmap(val_pred_par3, \n",
    "        annot=True,\n",
    "        linewidths=0.3,\n",
    "        robust=True,\n",
    "        cmap=sns.light_palette(\"seagreen\", as_cmap=True),\n",
    "        vmin=0, vmax=7, \n",
    "    #     center=0.5,\n",
    "        annot_kws={'size': 14},\n",
    "        ax=ax4, fmt='.10g'\n",
    "    )\n",
    "    ax4.set_xticklabels(\n",
    "        ax4.get_xticklabels(),\n",
    "        rotation=0,\n",
    "        horizontalalignment='center'\n",
    "    );\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed159d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def func4(risk_segment,allocation,existing_comms,paid_file):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a39571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21915369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3390d5de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc6ace4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
